{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La différentiation automatique et un début de *deep learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelques liens pour aller plus loin :\n",
    "* [Autodiff](https://github.com/maximiliense/lmpirp/blob/main/Notes/Automatic_differentiation.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vu précédemment, un grand nombre de modèles de *machine learning* s'appuient sur des algorithmes d'optimisation de type \"descente de gradient\". Ces algorithmes requièrent le calcul du gradient à chaque itération. Nous avons pu voir pour la régression linéaire et la régression logistique que cela était assez fastidieux. Ainsi, en pratique, on ne se sert que de modèles déjà codés et où il n'est pas nécessaire de fournir le gradient.\n",
    "\n",
    "Le *deep learning*, à l'inverse, s'appuie sur une quantité incroyable de modèles, customisés à la moindre occasion. Le *deep learning* n'échappe pas à la règle et est également optimisé au travers d'algorithmes d'optimisation de type \"descente de gradient\". Heureusement, il n'est pas nécessaire de calculer le gradient à la main de ces fonctions immenses. Les *frameworks* de *deep learning* sont en effet avant tout des *frameworks* de différentiation automatique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premiers tests avec Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Exercice 1 :**</span> **Commençons simple. Soit la fonction suivante :\n",
    "\\begin{equation}\n",
    "f(x)=3x+5\n",
    "\\end{equation}\n",
    "Calculer $\\frac{\\partial f}{\\partial x}(0)$ à la main et via *torch*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "\n",
    "###############################################################\n",
    "print('La derivee en 0 de f est', float(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Exercice 2 :**</span> **Un tout petit peu plus compliqué. Soit la fonction suivante :\n",
    "\\begin{equation}\n",
    "f(x)=2^x\n",
    "\\end{equation}\n",
    "Calculer $\\frac{\\partial f}{\\partial x}(0)$ à la main et via *torch*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "\n",
    "###############################################################\n",
    "print('La derivee en 0 de f est', float(x.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Exercice 3 :**</span> **Encore un peu plus compliqué, le gradient des moindres carrés. Calculer $\\frac{\\partial f}{\\partial \\boldsymbol{\\beta}}(\\boldsymbol{0})$ en utilisant les résultats des TPs précedents.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_beta = torch.rand(size=(2, 1))*2-1\n",
    "\n",
    "def sample_data(n):\n",
    "    X = torch.rand(size=(n, 2))\n",
    "    y = torch.matmul(X, real_beta) + torch.randn(size=(n, 1))\n",
    "    return X, y\n",
    "\n",
    "X, y = sample_data(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.zeros(size=(2, 1), requires_grad=True)\n",
    "\n",
    "print('Le gradient \"a la main\" est :\\n', -2*torch.matmul(X.transpose(1, 0), y))\n",
    "\n",
    "####### Complete this part ######## or die ####################\n",
    "\n",
    "###############################################################\n",
    "\n",
    "print('Le gradient via auto-differentiation:\\n', beta.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La descente de gradient et plus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme de descente de gradient, dans sa vesion la plus simple, consiste à se déplacer dans le sens opposé au gradient $\\nabla \\mathcal{L}(\\beta)$ à une vitesse proportionnelle au \"pas\" $\\eta>0$. Dit autrement, l'opération de mise à jour s'exprime de la manière suivante :\n",
    "\\begin{equation}\n",
    "\\beta^{(t)}=\\beta^{(t-1)}-\\eta\\nabla\\mathcal{L}(\\beta^{(t-1)})\n",
    "\\end{equation}\n",
    "\n",
    "Différentes stratégies ont été proposées afin d'améliorer les performances de l'algorithme. On peut citer le *momentum* qui consiste à conserver une inertie permettant de controller les phénomènes d'oscillation qui pourraient apparaître. De manière plus précise, transforme l'étape d'itération de la descente de gradient de la manière suivante :\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "z^{(t)}&=\\rho z^{(t-1)}+\\nabla\\mathcal{L}(\\beta^{(t-1)})\\\\\n",
    "\\beta^{(t)}&=\\beta^{(t-1)}-\\eta z^{(t)}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "où $\\rho$ est le paramètre du *momentum* et $\\eta$ le pas d'optimisation. On remarque que si $\\rho=0$, on retombe bien sur la descente de gradient traditionnelle. Cependant, si $\\rho>0$  (généralement $<1$), le pas d'optimisation devient une combinaison linéaire entre le gradient à l'itération courante et les gradients des itérations précédentes. En effet, on a bien $z^{(1)}=\\rho\\cdot 0+\\nabla\\mathcal{L}(\\beta^{(0)})=\\mathcal{L}(\\beta^{(0)})$, puis $z^{(2)}=\\rho\\cdot \\mathcal{L}(\\beta^{(0)})+\\mathcal{L}(\\beta^{(1)})$, puis $z^{(3)}=\\rho^2\\cdot\\mathcal{L}(\\beta^{(0)})+\\rho\\cdot\\mathcal{L}(\\beta^{(1)})+\\mathcal{L}(\\beta^{(2)})$, etc. Ainsi, si les gradients commencent à s'inverser d'une itération à l'autre (on oscille), la somme tendra à atténuer cet effet et la direction de mise à jour sera plus stable.\n",
    "\n",
    "\n",
    "Les librairies comme *torch* proposent de gérer tout cela sans que nous ayons à nous en occuper via, par exemple, la classe $\\texttt{optim.SGD}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice 1 :**</span> **Complétez la méthode $\\texttt{optimize}$ de la classe LeastSquare ci-dessous. Le tableau $\\texttt{loss_values}$ doit contenir les valeurs obtenues à chaque itération.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "class LeastSquare(object):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.beta = None\n",
    "    \n",
    "    def loss(self, beta):\n",
    "        errors = (torch.matmul(self.X, beta)-self.y) ** 2\n",
    "        return errors.sum()/self.X.shape[0]\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if self.beta is not None:\n",
    "            return torch.matmul(x, self.beta)\n",
    "    \n",
    "    def optimize(self, nb_iterations=40, momentum=0.0, lr=0.1):\n",
    "        \n",
    "        self.beta = torch.zeros(size=(2, 1), requires_grad=True).float()\n",
    "        ####### Complete this part ######## or die ####################\n",
    "        \n",
    "        ###############################################################\n",
    "        return loss_values\n",
    "        \n",
    "loss = LeastSquare(X, y)\n",
    "val_nomomentum = loss.optimize(lr=0.2)\n",
    "val_momentum = loss.optimize(momentum=0.3, lr=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# configuration generale de matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 8.0)\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot([i for i in range(1, len(val_nomomentum)+1)], val_nomomentum, label='No momentum')\n",
    "plt.plot([i for i in range(1, len(val_momentum)+1)], val_momentum, label='Momentum')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">**Question :**</span> **Comment expliquez-vous qu'un *momentum* bien configuré puisse accélérer l'optimisation ? Inspirez-vous de ce lien pour bien comprendre l'effet du *momentum* : [Animation momentum](https://distill.pub/2017/momentum/).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N'hésitez pas à passer via [http://colab.research.google.com](http://colab.research.google.com) pour les exercices qui suivent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'extérieur complexe, le *deep learning* n'est en réalité qu'une composition et une combinaison linéaire de fonctions plus élémentaires comme celles que nous avons vu jusque là. Récupérons un jeu de données connu : $\\texttt{CIFAR10}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objet $\\texttt{transform}$ permettra de normaliser les données qui seront données à notre modèle. En $\\texttt{pytorch}$, les données sont gérées par un *data loader*. En effet, on ne traite que très rarement tout le jeu de données d'un coup. On estime plutôt le gradient via un *batch* de données. De meilleurs résultats sont généralement observés lorsque le jeu de données est mélangé entre chaque itération d'optimisation. \n",
    "\n",
    "Regardons le jeu de données que nous sommes entrain de manipuler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print('\\t'.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de faciliter la manipulation de notre réseau de neuronnes, il est d'usage de l'encapsuler dans une classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:blue\">**Exercice 1 :**</span> **Proposez le code permettant d'optimiser votre réseau pendant deux *epochs*.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Complete this part ######## or die ####################\n",
    "\n",
    "###############################################################\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'notre_model.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
